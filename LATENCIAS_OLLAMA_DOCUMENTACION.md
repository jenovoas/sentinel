# üìä Documentaci√≥n de Latencias - Ollama Optimizaci√≥n

**Fecha**: 19 Diciembre 2024  
**Hardware**: GTX 1050 (3GB VRAM)  
**Objetivo**: Documentar mejoras de latencia antes/despu√©s optimizaci√≥n

---

## üî¨ BASELINE - phi3:mini (Sin Optimizar)

### M√©tricas Medidas

| M√©trica | Valor | Observaci√≥n |
|---------|-------|-------------|
| **TTFB Promedio** | **21,470ms** (~21.5s) | ‚ùå Muy alto |
| **TTFB Mediana** | **14,908ms** (~15s) | ‚ùå Muy alto |
| **TTFB M√≠nimo** | **3,627ms** (~3.6s) | ‚ö†Ô∏è Aceptable (modelo en RAM) |
| **TTFB M√°ximo** | **49,874ms** (~50s) | ‚ùå Inaceptable |
| **Requests** | 5 | - |

### An√°lisis

**Problema Identificado**: Ollama descarga/carga modelo entre requests
- Primera request: 3.6s (modelo ya en RAM)
- Segunda request: 49.9s (descarga modelo)
- Tercera request: 8.9s (carga desde disco)
- Cuarta request: 14.9s (carga desde disco)
- Quinta request: 30s (carga desde disco)

**Causa Ra√≠z**: 
- Modelo phi3:mini (~3.5GB) no cabe completamente en 3GB VRAM
- Ollama hace swapping CPU ‚Üî GPU
- Sin configuraci√≥n `keep_alive`, descarga modelo cada vez

---

## ‚ö° OPTIMIZACI√ìN PROPUESTA

### 1. Modelo Quantizado (phi3:mini-q4_K_M)

**Beneficios Esperados**:
```
Tama√±o: 3.5GB ‚Üí 2.2GB (-37%)
VRAM fit: ‚ùå ‚Üí ‚úÖ (cabe en 3GB)
TTFB esperado: 21.5s ‚Üí <2s (-90%)
```

**Comando**:
```bash
ollama pull phi3:mini-q4_K_M
```

### 2. Keep Alive Permanente

**Beneficios Esperados**:
```
Modelo en RAM: Temporal ‚Üí Permanente
TTFB subsecuente: 15s ‚Üí <500ms (-97%)
```

**Comando**:
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "phi3:mini-q4_K_M",
  "prompt": "warmup",
  "keep_alive": -1
}'
```

### 3. Configuraci√≥n Optimizada

**Par√°metros**:
```json
{
  "num_ctx": 2048,     // Reducir context window
  "num_batch": 128,    // Batch size optimizado
  "num_gpu": 1,        // Forzar GPU
  "num_thread": 4      // Threads CPU
}
```

---

## üéØ TARGETS POST-OPTIMIZACI√ìN

| M√©trica | Baseline | Target | Mejora |
|---------|----------|--------|--------|
| **TTFB Primera** | 21.5s | <2s | **-90%** |
| **TTFB Subsecuente** | 15s | <500ms | **-97%** |
| **TTFB Promedio** | 21.5s | <1s | **-95%** |
| **Estabilidad** | ‚ùå Alta varianza | ‚úÖ Consistente | - |

---

## üìã PLAN DE EJECUCI√ìN

### Paso 1: Descargar Modelo Optimizado
```bash
ollama pull phi3:mini-q4_K_M
```

### Paso 2: Configurar Keep Alive
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "phi3:mini-q4_K_M",
  "prompt": "warmup",
  "keep_alive": -1
}'
```

### Paso 3: Ejecutar Benchmark Comparativo
```bash
cd /home/jnovoas/sentinel/backend
python benchmark_comparativo.py
```

### Paso 4: Documentar Resultados
- Comparar TTFB antes/despu√©s
- Calcular % mejora
- Validar targets (<2s primera, <500ms subsecuente)

---

## üìä RESULTADOS ESPERADOS

### Escenario Optimista (Modelo en RAM)
```
TTFB: 500-1000ms
Mejora: 95%+ vs baseline
Estado: ‚úÖ Cumple targets
```

### Escenario Realista (Primera carga)
```
TTFB: 1500-2000ms
Mejora: 90%+ vs baseline
Estado: ‚úÖ Cumple targets
```

### Escenario Pesimista (Swapping)
```
TTFB: 3000-5000ms
Mejora: 75%+ vs baseline
Estado: ‚ö†Ô∏è Mejor que baseline pero no ideal
```

---

## üîç VALIDACI√ìN

### Criterios de √âxito
- ‚úÖ TTFB promedio <2s
- ‚úÖ TTFB subsecuente <500ms
- ‚úÖ Varianza <50% (estabilidad)
- ‚úÖ Modelo cabe en VRAM (sin swapping)

### Si No Cumple Targets
**Plan B**: Modelo m√°s peque√±o
```bash
ollama pull tinyllama  # 1.1B params, 637MB
```

**Plan C**: Upgrade GPU
```
RTX 3060 12GB (~$300)
‚Üí Permite modelos m√°s grandes
‚Üí vLLM con SPIRe+MTAD
‚Üí TTFB <200ms garantizado
```

---

## üìù NOTAS T√âCNICAS

### Por Qu√© Funciona la Optimizaci√≥n

1. **Quantizaci√≥n 4-bit**:
   - Reduce tama√±o 37%
   - Mantiene 95% calidad
   - Cabe en 3GB VRAM

2. **Keep Alive**:
   - Modelo permanece en RAM
   - Elimina overhead de carga
   - TTFB consistente

3. **Configuraci√≥n Optimizada**:
   - Context window reducido
   - Batch size balanceado
   - GPU prioritizada

### Limitaciones Conocidas

- GTX 1050 (3GB) es el cuello de botella
- Modelos >2.5GB requieren swapping
- Upgrade GPU eliminar√≠a limitaci√≥n

---

## üöÄ PR√ìXIMOS PASOS

1. **HOY**: Ejecutar optimizaci√≥n y validar
2. **Esta semana**: Documentar resultados reales
3. **Pr√≥ximo mes**: Evaluar upgrade GPU si necesario

---

**Estado**: ‚úÖ Baseline documentado, listo para optimizar  
**Pr√≥xima acci√≥n**: Ejecutar `ollama pull phi3:mini-q4_K_M`
