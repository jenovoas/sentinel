{
  "name": "AI-Powered Workflow Generator",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "minutes",
              "minutesInterval": 5
            }
          ]
        }
      },
      "id": "schedule",
      "name": "Every 5 minutes",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [250, 300]
    },
    {
      "parameters": {
        "url": "http://host.docker.internal:11434/api/generate",
        "method": "POST",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "mistral:latest"
            },
            {
              "name": "prompt",
              "value": "Genera un plan de monitoreo para un sistema observability en JSON"
            },
            {
              "name": "stream",
              "value": false
            }
          ]
        }
      },
      "id": "ollama-call",
      "name": "Call Ollama (Local AI)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [450, 300]
    },
    {
      "parameters": {
        "jsCode": "return {\n  response: $json.response,\n  timestamp: new Date().toISOString()\n}"
      },
      "id": "code-process",
      "name": "Process AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [650, 300]
    }
  ],
  "connections": {
    "Every 5 minutes": {
      "main": [
        [
          {
            "node": "Call Ollama (Local AI)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Ollama (Local AI)": {
      "main": [
        [
          {
            "node": "Process AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  }
}
