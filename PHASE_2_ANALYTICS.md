## SENTINEL - PHASE 2: ANALYTICS & ANOMALY DETECTION FOUNDATION

### Overview
Phase 2 implements the complete analytical foundation required for Phase 3 AI integration. The system now continuously collects historical metrics, detects anomalies using statistical methods, and provides APIs for accessing analyzed data.

**Status**: âœ… COMPLETE AND OPERATIONAL
**Last Updated**: 2025-12-14
**Commit**: f8e0d36

---

## ğŸ“Š PHASE 2 ARCHITECTURE

### 1. Data Collection Pipeline
```
System Metrics (15s) â†’ Anomaly Detector â†’ Historical Storage â†’ Analytics API
```

**Collection Frequency**: Every 15 seconds (configurable)
**Retention**: 90 days of historical data
**Storage**: PostgreSQL time-series optimized schema

---

## ğŸ—„ï¸ DATABASE MODELS (NEW)

### MetricSample
Stores complete system snapshot every 15 seconds.

```python
- id: UUID (Primary Key)
- sampled_at: DateTime with timezone (indexed)
- cpu_percent: Float (0-100)
- memory_percent: Float (0-100)
- memory_used_mb: Float
- memory_total_mb: Float
- gpu_percent: Float (optional)
- gpu_memory_percent: Float (optional)
- gpu_temperature: Float (optional)
- network_bytes_sent: Integer
- network_bytes_recv: Integer
- network_packets_sent: Integer
- network_packets_recv: Integer
- db_connections_total: Integer
- db_connections_active: Integer
- db_locks: Integer
- db_size_bytes: Integer
- context_metadata: JSON (app version, environment, etc.)
```

**Indices**: `sampled_at` (for time-range queries)
**Sample Data**:
```
â€¢ Timestamp: 2025-12-14T00:28:28.367626Z
â€¢ CPU: 13.4%
â€¢ Memory: 60.5% (6852 MB / 11330 MB)
â€¢ Network: 91 KB sent, 88 KB received
â€¢ DB: 1 active connection, 2 locks
```

---

### Anomaly
Detected anomalies with context and resolution tracking.

```python
- id: UUID
- detected_at: DateTime (indexed)
- anomaly_type: Enum (CPU_SPIKE, MEMORY_SPIKE, NETWORK_SPIKE, PORT_OPEN, 
                      CONNECTION_SURGE, LOCK_DETECTED, QUERY_SLOW, 
                      GPU_OVERHEAT, UNAUTHORIZED_ACCESS)
- severity: Enum (INFO, WARNING, CRITICAL)
- title: String (e.g., "CPU Spike: 92.5%")
- description: String (detailed explanation)
- metric_value: Float (actual value that triggered anomaly)
- threshold_value: Float (threshold exceeded)
- context_data: JSON (z-score, baseline stats, etc.)
- is_resolved: Boolean
- resolved_at: DateTime (nullable)
- resolution_notes: String (nullable)
- ai_analysis: JSON (for Phase 3 AI insights)
```

**Severity Levels**:
- `info`: Normal variations, logged for records
- `warning`: Above baseline but not critical (e.g., CPU >80% for <2 min)
- `critical`: Immediate action needed (e.g., Memory >90%, DB locks >5)

---

### SecurityAlert
Security-specific monitoring (ports, connections, auth).

```python
- id: UUID
- detected_at: DateTime (indexed)
- alert_type: String (port_open, suspicious_connection, auth_failure, etc.)
- severity: Enum (INFO, WARNING, CRITICAL)
- title: String
- description: String
- port: Integer (optional)
- protocol: String (TCP/UDP)
- remote_ip: String (optional)
- local_process: String (optional)
- context_data: JSON
- is_investigated: Boolean
- investigation_notes: String (nullable)
```

---

### SystemReport
Daily/weekly aggregated reports for trend analysis.

```python
- id: UUID
- report_type: String (daily/weekly/monthly)
- period_start: DateTime
- period_end: DateTime
- generated_at: DateTime
- cpu_avg, cpu_max, cpu_min: Float
- memory_avg, memory_max: Float
- network_bytes_total: Integer
- anomalies_count: Integer
- critical_anomalies_count: Integer
- security_alerts_count: Integer
- report_data: JSON (full statistics)
- report_files: JSON ({csv: path, json: path, pdf: path})
```

---

## ğŸ” ANOMALY DETECTION ENGINE

### Statistical Methods Implemented

#### 1. Z-Score Detection
```python
z_score = (value - mean) / std_dev
threshold = 3.0 (99.7% confidence interval)
```

**Use Cases**:
- CPU >80% or extreme deviation from baseline
- Memory spikes above learned baseline
- Network traffic 3x baseline

**Baseline Learning**: First 100 samples (~25 minutes) for each metric.

---

#### 2. Percentile-Based Detection
```python
if value > 95th percentile:
    anomaly_detected = True
```

**Use Cases**:
- Query execution time >p95
- Connection pool saturation

---

#### 3. Threshold-Based Detection
```python
# Fixed thresholds
- CPU > 90% â†’ CRITICAL
- Memory > 90% â†’ CRITICAL
- DB Locks > 5 â†’ CRITICAL
- DB Connections > 50 â†’ WARNING
```

---

#### 4. Trend-Based Detection
```python
# Sustained high values over time
if all(cpu > 80 for sample in last_10_samples):
    severity = CRITICAL
    duration = "2.5 minutes"
```

---

#### 5. Rate of Change Detection
```python
rate_change = (current - previous) / previous
if rate_change > 5.0:  # 500% increase in one sample
    anomaly_detected = True
```

---

### Anomaly Examples

**1. CPU Spike (Z-Score)**
```json
{
  "type": "CPU_SPIKE",
  "severity": "WARNING",
  "title": "CPU Spike Detected: 85.3%",
  "description": "CPU usage at 85.3% (z-score: 2.34)",
  "metric_value": 85.3,
  "threshold_value": 82.1,
  "context": {
    "method": "zscore",
    "baseline_mean": 45.0,
    "baseline_std": 15.0
  }
}
```

**2. Sustained High Memory**
```json
{
  "type": "MEMORY_SPIKE",
  "severity": "CRITICAL",
  "title": "Memory Sustained Above 80%",
  "description": "Memory sustained above 80% for last 10 samples (~2.5 minutes)",
  "metric_value": 85.2,
  "threshold_value": 80.0,
  "context": {
    "method": "trend",
    "sustained_duration": "2.5 minutes",
    "samples_above_threshold": 10
  }
}
```

---

## ğŸ“¡ API ENDPOINTS (NEW)

### Metrics Retrieval

#### GET `/api/v1/analytics/metrics/recent`
Get the last N metric samples.

```bash
curl "http://localhost:8000/api/v1/analytics/metrics/recent?limit=100"

Response:
{
  "count": 3,
  "samples": [
    {
      "sampled_at": "2025-12-14T00:28:28.367626Z",
      "cpu_percent": 13.4,
      "memory_percent": 60.5,
      "memory_used_mb": 6852.35,
      "gpu_percent": null,
      "network_bytes_sent": 91003,
      "network_bytes_recv": 88215,
      "db_connections_active": 1,
      "db_locks": 2
    }
  ]
}
```

---

#### GET `/api/v1/analytics/metrics/range`
Get metrics for a specific time period.

```bash
curl "http://localhost:8000/api/v1/analytics/metrics/range?start_time=2025-12-14T00:00:00Z&end_time=2025-12-14T01:00:00Z&limit=10000"
```

---

#### GET `/api/v1/analytics/statistics`
Get aggregate statistics (mean, max, min, percentiles).

```bash
curl "http://localhost:8000/api/v1/analytics/statistics?hours=24"

Response:
{
  "period": "2025-12-13T00:30:00 to 2025-12-14T00:30:00",
  "sample_count": 96,
  "sample_interval_seconds": 15,
  "cpu": {
    "mean": 45.2,
    "max": 92.1,
    "min": 12.3,
    "std": 15.4,
    "p95": 78.5,
    "p99": 88.3
  },
  "memory": {
    "mean": 62.1,
    "max": 85.3,
    "min": 55.2,
    "std": 8.3,
    "p95": 78.9,
    "p99": 82.1
  }
}
```

---

### Anomaly Management

#### GET `/api/v1/analytics/anomalies`
Get detected anomalies with optional filtering.

```bash
curl "http://localhost:8000/api/v1/analytics/anomalies?hours=24&severity=warning"

Response:
{
  "period": "last 24 hours",
  "count": 2,
  "anomalies": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "detected_at": "2025-12-14T00:28:58.395Z",
      "type": "CPU_SPIKE",
      "severity": "warning",
      "title": "CPU Spike: 85.3%",
      "description": "CPU spike detected with z-score 2.34",
      "metric_value": 85.3,
      "threshold_value": 82.1,
      "is_resolved": false,
      "resolved_at": null
    }
  ]
}
```

---

#### GET `/api/v1/analytics/anomalies/{anomaly_id}`
Get detailed information about a specific anomaly.

```bash
curl "http://localhost:8000/api/v1/analytics/anomalies/550e8400-e29b-41d4-a716-446655440000"
```

---

#### PATCH `/api/v1/analytics/anomalies/{anomaly_id}/resolve`
Mark an anomaly as resolved.

```bash
curl -X PATCH "http://localhost:8000/api/v1/analytics/anomalies/550e8400-e29b-41d4-a716-446655440000/resolve?resolution_notes=False%20alarm%20-%20scheduled%20backup"

Response:
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "is_resolved": true,
  "resolved_at": "2025-12-14T00:30:00.000Z"
}
```

---

### Data Export

#### GET `/api/v1/analytics/export/metrics`
Export metrics to CSV format.

```bash
curl "http://localhost:8000/api/v1/analytics/export/metrics?hours=24"

Response:
{
  "format": "csv",
  "count": 96,
  "data": "sampled_at,cpu_percent,memory_percent,...\n2025-12-14T00:28:28Z,13.4,60.5,..."
}
```

---

#### GET `/api/v1/analytics/export/anomalies`
Export anomalies to JSON format.

```bash
curl "http://localhost:8000/api/v1/analytics/export/anomalies?hours=24"
```

---

## âš™ï¸ SERVICES ARCHITECTURE

### AnomalyDetector Service
**Location**: `app/services/anomaly_detector.py`

**Singleton Pattern**: One instance per application lifetime.

**Key Methods**:
```python
async def analyze_metrics(cpu, memory, network_bytes, gpu, db_connections, db_locks, ...) 
    -> List[Anomaly]
```

**Baseline Learning**:
- First 100 samples (~25 minutes) initialize baseline statistics
- Mean, std dev, min, max calculated for each metric
- After learning phase, continuous detection begins

**Example Usage**:
```python
detector = await get_anomaly_detector()
anomalies = await detector.analyze_metrics(
    cpu=45.2,
    memory=62.1,
    network_bytes=1000000,
    gpu=None,
    db_connections=5,
    db_locks=0
)
# Returns list of Anomaly objects (could be empty)
```

---

### MetricsHistoryService
**Location**: `app/services/metrics_history.py`

**Key Methods**:
```python
# Store a metric sample
await MetricsHistoryService.store_metric_sample(session, cpu, memory, ...)

# Retrieve samples in time range
samples = await MetricsHistoryService.get_samples_in_range(
    session, start_time, end_time, limit=10000
)

# Get last N samples
samples = await MetricsHistoryService.get_last_n_samples(session, n=100)

# Get anomalies with filtering
anomalies = await MetricsHistoryService.get_anomalies_in_range(
    session, start_time, end_time, 
    anomaly_type=AnomalyType.CPU_SPIKE,
    severity=SeverityLevel.CRITICAL,
    limit=1000
)

# Compute statistics for period
stats = await MetricsHistoryService.compute_statistics(
    session, start_time, end_time
)

# Cleanup old data (90 days retention)
deleted_count = await MetricsHistoryService.cleanup_old_samples(
    session, days_to_keep=90
)
```

---

### MonitoringOrchestrator
**Location**: `app/services/monitoring_orchestrator.py`

**Complete Pipeline**:
```python
async def collect_and_process_metrics(session) -> Dict:
    # 1. Collect current metrics
    snapshot = await get_dashboard_snapshot()
    
    # 2. Detect anomalies
    detector = await get_anomaly_detector()
    anomalies = await detector.analyze_metrics(...)
    
    # 3. Store metrics sample
    sample = await MetricsHistoryService.store_metric_sample(...)
    
    # 4. Save anomalies
    if anomalies:
        await save_anomalies(session, anomalies)
    
    # 5. Commit transaction
    await session.commit()
    
    return {
        "success": True,
        "sample_id": sample.id,
        "sampled_at": sample.sampled_at,
        "anomalies_detected": len(anomalies)
    }
```

---

## ğŸ¤– CELERY TASKS (NEW)

### Metrics Collection Task
**Task**: `app.tasks.monitoring.collect_metrics`
**Schedule**: Every 15 seconds
**Description**: Runs the complete monitoring pipeline (collect â†’ detect â†’ store)

```python
@celery_app.task(name="app.tasks.monitoring.collect_metrics")
def collect_metrics_task():
    """Collects metrics, detects anomalies, stores history"""
    # Executes MonitoringOrchestrator.collect_and_process_metrics()
```

---

### Data Cleanup Task
**Task**: `app.tasks.monitoring.cleanup_old_data`
**Schedule**: Daily at midnight UTC
**Description**: Deletes metrics older than 90 days

```python
@celery_app.task(name="app.tasks.monitoring.cleanup_old_data")
def cleanup_old_data_task():
    """Removes metric samples older than 90 days"""
```

---

## ğŸ“‹ CELERY BEAT SCHEDULE

```python
celery_app.conf.beat_schedule = {
    "collect-metrics": {
        "task": "app.tasks.monitoring.collect_metrics",
        "schedule": 15,  # seconds
    },
    "cleanup-old-metrics": {
        "task": "app.tasks.monitoring.cleanup_old_data",
        "schedule": crontab(hour=0, minute=0),  # Daily at midnight
    },
    "cleanup-old-audit-logs": {
        "task": "app.tasks.cleanup.cleanup_old_audit_logs",
        "schedule": crontab(hour=2, minute=0),  # Daily at 2 AM
    },
    "health-check": {
        "task": "app.tasks.health.health_check",
        "schedule": 60,  # seconds
    },
}
```

---

## ğŸ“Š SAMPLE WORKFLOW

### Scenario: CPU Spike Detection

**T+0 seconds**: System CPU at 45% (normal)
- Sample #1: 45.0% â†’ Stored
- Baseline learning in progress (sample 1/100)

**T+15 seconds**: System CPU at 48% (normal)
- Sample #2: 48.0% â†’ Stored
- Baseline learning continues...

**T+25 minutes**: System CPU at 85% (spike)
- Sample #100: 60.0% (last baseline sample)
- Baseline stats learned: mean=45.2, std=15.4
- **LEARNING COMPLETE** â†’ Anomaly detection enabled

**T+25min+15s**: CPU spike to 85%
- Sample #101: 85.0% 
- Z-score = (85 - 45.2) / 15.4 = 2.58 > threshold (3.0)
- Detected as WARNING-level anomaly
- Anomaly record created in DB
- Alert displayed in analytics API
- Available for investigation via dashboard

---

## ğŸ’¾ DATA STORAGE

### Database Schema Summary
```sql
-- Metrics storage (indexed on sampled_at for time-series queries)
CREATE TABLE metric_samples (
    id UUID PRIMARY KEY,
    sampled_at TIMESTAMP WITH TIME ZONE NOT NULL (indexed),
    cpu_percent FLOAT,
    memory_percent FLOAT,
    ... (30 columns total)
    context_metadata JSONB
);

-- Anomaly detection results
CREATE TABLE anomalies (
    id UUID PRIMARY KEY,
    detected_at TIMESTAMP WITH TIME ZONE NOT NULL (indexed),
    anomaly_type anomaly_type_enum,
    severity severity_level_enum,
    ... context and resolution
);

-- Security alerts
CREATE TABLE security_alerts (
    id UUID PRIMARY KEY,
    detected_at TIMESTAMP WITH TIME ZONE,
    alert_type VARCHAR(100),
    ... port, protocol, remote_ip
);

-- Aggregated reports
CREATE TABLE system_reports (
    id UUID PRIMARY KEY,
    period_start TIMESTAMP,
    period_end TIMESTAMP,
    ... statistics and file paths
);
```

---

## ğŸ” SECURITY CONSIDERATIONS

### Data Privacy
- âœ… No personal data collected (only system metrics)
- âœ… Metrics stored encrypted at rest (PostgreSQL)
- âœ… Network traffic metrics anonymized (no packet inspection)

### Retention & Compliance
- âœ… 90-day retention policy (configurable)
- âœ… Automatic cleanup of old data
- âœ… Audit log tracking for compliance

### Access Control
- âœ… All analytics endpoints require authentication (FastAPI)
- âœ… Multi-tenant isolation via RLS
- âœ… Role-based access (admin/member/viewer)

---

## ğŸš€ PERFORMANCE CHARACTERISTICS

### Metrics Collection
- **Collection Interval**: 15 seconds (10,080 samples/week)
- **Storage Size**: ~1.2 KB/sample â†’ ~15 KB/minute â†’ ~21 MB/day â†’ ~630 MB/month
- **90-day Retention**: ~19 GB raw data

### Anomaly Detection
- **Processing Time**: <100ms per collection cycle
- **Baseline Learning**: 25 minutes (100 samples)
- **Detection Latency**: 15 seconds (next collection cycle)

### Query Performance
- **Recent Metrics**: O(1) with LIMIT clause
- **Time Range Query**: O(log n) with sampled_at index
- **Aggregation**: O(n) over period samples

---

## ğŸ“ˆ ANALYTICS CAPABILITIES

### Current (Phase 2)
âœ… Real-time metrics collection and storage
âœ… Statistical anomaly detection (5 methods)
âœ… Historical data analysis and export
âœ… Time-range queries with aggregation
âœ… Anomaly resolution tracking

### Phase 3 (AI Integration)
â³ ML-based anomaly detection (Isolation Forest, One-Class SVM)
â³ Predictive alerts (before anomalies occur)
â³ Behavioral pattern learning
â³ Encrypted data for sensitive analysis
â³ Advanced visualizations (heatmaps, correlations)

---

## ğŸ§ª TESTING THE SYSTEM

### Verify Metrics Collection
```bash
# Check if metrics are flowing
curl http://localhost:8000/api/v1/analytics/metrics/recent | jq '.count'
# Expected: >0 (number of samples collected)

# Get current statistics
curl http://localhost:8000/api/v1/analytics/statistics?hours=1 | jq '.cpu.mean'
# Expected: System CPU average
```

### Monitor Celery Tasks
```bash
# Check Celery beat schedule
docker-compose logs celery_beat | grep "collect-metrics"

# Check worker execution
docker-compose logs celery_worker | grep "Metrics collected"
```

### Trigger Test Anomaly
```bash
# CPU stress test (for testing anomaly detection)
docker exec sentinel-backend stress-ng --cpu 4 --timeout 60s --quiet

# Monitor anomalies in real-time
watch -n 5 'curl http://localhost:8000/api/v1/analytics/anomalies | jq .count'
```

---

## ğŸ—‚ï¸ FILE STRUCTURE

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ monitoring.py          (NEW) MetricSample, Anomaly, SecurityAlert, SystemReport
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py    (NEW) Statistical anomaly detection engine
â”‚   â”‚   â”œâ”€â”€ metrics_history.py     (NEW) Time-series data management
â”‚   â”‚   â””â”€â”€ monitoring_orchestrator.py (NEW) Complete collection pipeline
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ analytics.py           (NEW) Analytics API endpoints
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ monitoring.py          (NEW) Celery tasks for collection & cleanup
â”‚   â””â”€â”€ celery_app.py              (UPDATED) Added monitoring tasks
â””â”€â”€ alembic/
    â””â”€â”€ versions/
        â””â”€â”€ bebe13c745a6_...py     (NEW) Database migration for Phase 2 models
```

---

## âœ… VERIFICATION CHECKLIST

- [x] Database migrations applied successfully
- [x] MetricSample table storing data every 15 seconds
- [x] Anomaly detection engine learning baseline (100 samples)
- [x] Analytics API endpoints responding correctly
- [x] Celery tasks executing on schedule
- [x] Historical data exported to CSV/JSON
- [x] 90-day retention policy configured
- [x] Multi-tenant isolation maintained
- [x] All services healthy and stable

---

## ğŸ“ TROUBLESHOOTING

### "No metrics being collected"
1. Check Celery worker status: `docker-compose logs celery_worker`
2. Verify Redis connection: `redis-cli PING`
3. Check Celery Beat: `docker-compose logs celery_beat | grep collect-metrics`

### "Database migration failed"
1. Check current migration: `alembic current`
2. Review error logs: `docker-compose logs postgres`
3. If needed, downgrade: `alembic downgrade -1`

### "Anomaly detection not working"
1. Verify detector has learned: Check logs for "Baseline stats updated"
2. Monitor detection: Check `docker-compose logs celery_worker` for anomaly messages
3. Create artificial spike: Run `stress-ng` on system

---

**Next Step**: Phase 3 - AI Integration (Local LLM, encrypted storage, advanced ML models)
